{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3ef6158-e5c5-4691-8cb8-0b72e16465e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is not available. Running on CPU.\n",
      "CPU Model: Intel(R) Xeon(R) CPU E5-2650 v3 @ 2.30GHz\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import platform\n",
    "import psutil\n",
    "import re\n",
    "import subprocess\n",
    "\n",
    "def get_cpu_model_linux():\n",
    "    \"\"\"Get CPU model name on Linux using /proc/cpuinfo or lscpu.\"\"\"\n",
    "    try:\n",
    "        # Method 1: Parse /proc/cpuinfo\n",
    "        with open(\"/proc/cpuinfo\", \"r\") as f:\n",
    "            for line in f:\n",
    "                if \"model name\" in line:\n",
    "                    return re.split(r\":\\s*\", line.strip())[1]\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to read /proc/cpuinfo: {e}\")\n",
    "    \n",
    "    try:\n",
    "        # Method 2: Use lscpu as fallback\n",
    "        result = subprocess.run([\"lscpu\"], capture_output=True, text=True)\n",
    "        for line in result.stdout.splitlines():\n",
    "            if \"Model name\" in line:\n",
    "                return re.split(r\":\\s*\", line.strip())[1]\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to run lscpu: {e}\")\n",
    "    \n",
    "    return \"Unknown CPU Model\"\n",
    "\n",
    "# Check if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available!\")\n",
    "    gpu_id = torch.cuda.current_device()\n",
    " #   print(f\"Current GPU ID: {gpu_id}\")\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(gpu_id)}\")\n",
    " #   print(f\"CUDA Capability: {torch.cuda.get_device_capability(gpu_id)}\")\n",
    " #   print(f\"Total Memory: {torch.cuda.get_device_properties(gpu_id).total_memory / 1e9:.2f} GB\")\n",
    " #   print(f\"Memory Allocated: {torch.cuda.memory_allocated(gpu_id) / 1e6:.2f} MB\")\n",
    " #   print(f\"Memory Cached: {torch.cuda.memory_reserved(gpu_id) / 1e6:.2f} MB\")\n",
    " #   print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Running on CPU.\")\n",
    "    print(f\"CPU Model: {get_cpu_model_linux()}\")\n",
    " #   print(f\"Processor: {platform.processor()}\")\n",
    " #   print(f\"CPU Name: {platform.machine()}\")\n",
    " #   print(f\"Physical Cores: {psutil.cpu_count(logical=False)}\")\n",
    " #   print(f\"Total Cores: {psutil.cpu_count(logical=True)}\")\n",
    " #   try:\n",
    " #       print(f\"CPU Frequency: {psutil.cpu_freq().current:.2f} MHz\")\n",
    " #   except:\n",
    " #       print(\"CPU Frequency: Not available\")\n",
    " #   print(f\"System: {platform.system()} {platform.release()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
