import torch
import torch.nn.functional as F
import cv2
import numpy as np
import matplotlib.pyplot as plt
import timeit
from utils.data_utils import process_data_tuple
from models.label_utils import get_label_mapping

def generate_attribution(image, predicted_class, model, patch_size=16):
    """
    Generate attribution using Ablation Studies (AS) for the given image.
    This method systematically occludes patches of the input image and measures the
    change in predicted probability for the target class.
    
    Parameters:
    - image: Tensor of shape [1, 3, H, W].
    - predicted_class: The target class for which to generate the explanation.
    - model: Pretrained model.
    - patch_size: Size of the patch to occlude (default: 16).
    
    Returns:
    - heatmap: A 2D tensor (upsampled to the original image size) showing the importance of each region.
    """
    model.eval()
    device = image.device

    # Compute the original probability for the predicted class
    with torch.no_grad():
        output = model(image)
        prob = F.softmax(output, dim=1)[0, predicted_class.item() if isinstance(predicted_class, torch.Tensor) else predicted_class]

    # Get spatial dimensions
    _, _, H, W = image.shape
    num_patches_h = H // patch_size
    num_patches_w = W // patch_size

    # Prepare an empty heatmap (one value per patch)
    heatmap = torch.zeros((num_patches_h, num_patches_w), device=device)

    # Define a baseline patch (black image)
    baseline = torch.zeros_like(image)

    # Systematically ablate each patch
    for i in range(num_patches_h):
        for j in range(num_patches_w):
            perturbed_image = image.clone()
            perturbed_image[:, :, i*patch_size:(i+1)*patch_size, j*patch_size:(j+1)*patch_size] = \
                baseline[:, :, i*patch_size:(i+1)*patch_size, j*patch_size:(j+1)*patch_size]
            with torch.no_grad():
                out_perturbed = model(perturbed_image)
                prob_perturbed = F.softmax(out_perturbed, dim=1)[0, predicted_class.item() if isinstance(predicted_class, torch.Tensor) else predicted_class]
            # The drop in probability indicates the importance of that patch.
            heatmap[i, j] = prob - prob_perturbed

    # Clamp negative values and normalize the heatmap to [0, 1]
    heatmap = torch.clamp(heatmap, min=0)
    if heatmap.max() > 0:
        heatmap = heatmap / heatmap.max()

    # Upsample the heatmap to the input image size
    heatmap = heatmap.unsqueeze(0).unsqueeze(0)  # shape: [1, 1, num_patches_h, num_patches_w]
    heatmap = F.interpolate(heatmap, size=(H, W), mode='bilinear', align_corners=False)
    return heatmap.squeeze()

def warm_up(model):
    """
    Run a warm-up pass to ensure memory and computation stability for Ablation Studies.
    """
    dummy_image = torch.randn(1, 3, 224, 224, device=next(model.parameters()).device)
    with torch.no_grad():
        output = model(dummy_image)
        _, predicted_class = torch.max(output, 1)
    _ = generate_attribution(dummy_image, predicted_class, model)

def visualize_attribution(image, attribution, label, label_names, model, model_name, save_path=None):
    """
    Visualize the Ablation Studies heatmap overlaid on the original image.
    
    Parameters:
    - image: Original input image tensor.
    - attribution: Attribution heatmap generated by the ablation method.
    - label: True label of the image (or None if not available).
    - label_names: List of class names.
    - model: Pretrained model.
    - model_name: The name of the model.
    - save_path: Optional file path to save the visualization.
    """
    with torch.no_grad():
        output = model(image)
        _, predicted_class = torch.max(output, 1)
    predicted_label, true_label = get_label_mapping(
        model_name=model_name,
        predicted_class=predicted_class,
        label=label,
        label_names=label_names
    )
    print(f"Model: {model_name}, Predicted: {predicted_label}, True: {true_label}")

    # Prepare the heatmap for visualization
    heatmap_np = attribution.cpu().numpy()
    heatmap_np = (heatmap_np * 255).astype(np.uint8)
    heatmap_colored = cv2.applyColorMap(heatmap_np, cv2.COLORMAP_JET)

    # Convert the original image to a NumPy array (assuming ImageNet normalization)
    img_np = image.squeeze().permute(1, 2, 0).cpu().numpy()
    img_np = np.clip((img_np * [0.229, 0.224, 0.225] + [0.485, 0.456, 0.406]) * 255, 0, 255).astype(np.uint8)
    heatmap_resized = cv2.resize(heatmap_colored, (img_np.shape[1], img_np.shape[0]))
    overlayed_img = cv2.addWeighted(img_np, 0.6, heatmap_resized, 0.4, 0)

    fig, axes = plt.subplots(1, 2, figsize=(10, 5))
    axes[0].imshow(img_np)
    axes[0].set_title("Input" if true_label == "Unknown" else f"True: {true_label}")
    axes[0].axis("off")
    axes[1].imshow(overlayed_img)
    axes[1].set_title(f"Predicted: {predicted_label}")
    axes[1].axis("off")
    fig.tight_layout()
    if save_path:
        fig.savefig(save_path, bbox_inches="tight", pad_inches=0.1)
        visualize_attribution.save_count += 1
        print(f"Saved visualization at {save_path}")
    plt.show()
    plt.close(fig)

# Initialize save counter attribute for visualization
visualize_attribution.save_count = 0

def measure_avg_time_across_images(data_source, model, generate_attribution):
    """
    Measure the average time taken to generate Ablation Studies attributions across images.
    
    Parameters:
    - data_source: A DataLoader or list of image tuples.
    - model: Pretrained model.
    - generate_attribution: Function to generate attributions.
    
    Returns:
    - avg_time_taken: Average time per image.
    - times: List of times for each image.
    """
    times = []
    for data_item in data_source:
        image, label = process_data_tuple(data_item, model)
        with torch.no_grad():
            output = model(image)
            _, predicted_class = torch.max(output, 1)
        start_time = timeit.default_timer()
        _ = generate_attribution(image, predicted_class, model)
        end_time = timeit.default_timer()
        times.append(end_time - start_time)
        torch.cuda.empty_cache()
    avg_time_taken = sum(times) / len(times)
    return avg_time_taken, times
