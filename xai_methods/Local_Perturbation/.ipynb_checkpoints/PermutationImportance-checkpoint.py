import torch
import torch.nn.functional as F
import cv2
import numpy as np
import matplotlib.pyplot as plt
import timeit
from utils.data_utils import process_data_tuple
from models.label_utils import get_label_mapping

def generate_attribution(image, predicted_class, model, patch_size=16):
    """
    Generate Permutation Importance (PI) attribution for the given image and class.
    The method occludes patches of the input image and measures the change in output probability.
    
    Parameters:
    - image: Tensor representing the input image (shape: [1, 3, H, W]).
    - predicted_class: Predicted class label for which we compute the attribution.
    - model: Pretrained model.
    - patch_size: Size of the patch to occlude (default: 16).
    
    Returns:
    - heatmap: A heatmap (2D tensor) of the same spatial size as the input image,
               indicating the importance of different regions.
    """
    model.eval()
    device = image.device

    # Compute the original probability for the predicted class
    with torch.no_grad():
        output = model(image)
        orig_prob = F.softmax(output, dim=1)[0, predicted_class.item()]
    
    # Get spatial dimensions
    _, _, H, W = image.shape
    num_patches_h = H // patch_size
    num_patches_w = W // patch_size

    # Prepare an empty heatmap (one value per patch)
    heatmap = torch.zeros((num_patches_h, num_patches_w), device=device)

    # Define a baseline patch (black image)
    baseline = torch.zeros_like(image)

    # Iterate over patches
    for i in range(num_patches_h):
        for j in range(num_patches_w):
            # Clone the original image and occlude one patch
            perturbed_image = image.clone()
            perturbed_image[:, :, i*patch_size:(i+1)*patch_size, j*patch_size:(j+1)*patch_size] = \
                baseline[:, :, i*patch_size:(i+1)*patch_size, j*patch_size:(j+1)*patch_size]
            
            with torch.no_grad():
                output = model(perturbed_image)
                perturbed_prob = F.softmax(output, dim=1)[0, predicted_class.item()]
            
            # The importance of the patch is how much the probability drops when occluded
            heatmap[i, j] = orig_prob - perturbed_prob

    # Normalize the heatmap to [0, 1]
    heat_min = heatmap.min()
    heat_max = heatmap.max()
    if (heat_max - heat_min) > 1e-8:
        heatmap = (heatmap - heat_min) / (heat_max - heat_min)
    else:
        heatmap.zero_()
    
    # Upsample the heatmap to the original image size
    heatmap = heatmap.unsqueeze(0).unsqueeze(0)  # shape: [1, 1, num_patches_h, num_patches_w]
    heatmap = F.interpolate(heatmap, size=(H, W), mode='bilinear', align_corners=False)
    heatmap = heatmap.squeeze()  # shape: [H, W]
    
    return heatmap


def warm_up(model):
    """
    Run a warm-up pass to ensure memory and computation stability.
    
    Parameters:
    - model: Pretrained model.
    """
    dummy_image = torch.randn(1, 3, 224, 224, device=next(model.parameters()).device)
    with torch.no_grad():
        output = model(dummy_image)
        _, predicted_class = torch.max(output, 1)
    _ = generate_attribution(dummy_image, predicted_class, model)


def visualize_attribution(image, attribution, label, label_names, model, model_name, save_path=None):
    """
    Visualize the Permutation Importance heatmap overlayed on the original image.
    
    Parameters:
    - image: Original input image tensor.
    - attribution: Attribution heatmap (2D tensor) generated by the PI method.
    - label: True label (or None for URL data).
    - label_names: List of class names for the dataset.
    - model: Pretrained model.
    - model_name: Name of the model.
    - save_path: Optional file path to save the visualization.
    """
    with torch.no_grad():
        output = model(image)
        _, predicted_class = torch.max(output, 1)
    
    # Get label mappings
    predicted_label, true_label = get_label_mapping(
        model_name=model_name,
        predicted_class=predicted_class,
        label=label,
        label_names=label_names,
    )
    
    print(f"Model: {model_name}, Predicted Class: {predicted_label}, True Class: {true_label}")
    
    # Process the heatmap for visualization
    heatmap_np = attribution.cpu().numpy()
    heatmap_np = (heatmap_np * 255).astype(np.uint8)
    heatmap_colored = cv2.applyColorMap(heatmap_np, cv2.COLORMAP_JET)
    
    # Convert the original image to a NumPy array (reverse normalization if needed)
    img_np = image.squeeze().permute(1, 2, 0).cpu().numpy()
    img_np = np.clip((img_np * [0.229, 0.224, 0.225] + [0.485, 0.456, 0.406]) * 255, 0, 255).astype(np.uint8)
    
    # Overlay heatmap on the original image
    overlayed_img = cv2.addWeighted(img_np, 0.6, heatmap_colored, 0.4, 0)
    
    # Plot the results
    fig, axes = plt.subplots(1, 2, figsize=(10, 5))
    axes[0].imshow(img_np)
    title_input = f'Input' if true_label == "Unknown" else f'True: {true_label}'
    axes[0].set_title(title_input)
    axes[0].axis('off')
    
    axes[1].imshow(overlayed_img)
    axes[1].set_title(f'Predicted: {predicted_label}')
    axes[1].axis('off')
    
    fig.tight_layout()
    
    if save_path:
        fig.savefig(save_path, bbox_inches="tight", pad_inches=0.1)
        visualize_attribution.save_count += 1
        print(f"Saved visualization at {save_path}")
    
    plt.show()
    plt.close(fig)

# Initialize the save counter as an attribute of the function
visualize_attribution.save_count = 0


def measure_avg_time_across_images(data_source, model, generate_attribution):
    """
    Measure the average time taken to generate Permutation Importance attributions across images.
    
    Parameters:
    - data_source: DataLoader or list of image tuples.
    - model: Pretrained model.
    - generate_attribution: Function to generate attributions.
    
    Returns:
    - avg_time_taken: Average time across images.
    - times: List of times per image.
    """
    times = []
    for data_item in data_source:
        image, label = process_data_tuple(data_item, model)
        with torch.no_grad():
            output = model(image)
            _, predicted_class = torch.max(output, 1)
        
        start_time = timeit.default_timer()
        _ = generate_attribution(image, predicted_class, model)
        end_time = timeit.default_timer()
        
        times.append(end_time - start_time)
        torch.cuda.empty_cache()
    
    avg_time_taken = sum(times) / len(times)
    return avg_time_taken, times
